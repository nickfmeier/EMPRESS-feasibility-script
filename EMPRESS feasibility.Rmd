---
title: "EMPRESS feasibility script"
author: "NM"
date: "2026-01-15"
output: html_document
---

## 1.0 Load libraries

```{r include=FALSE}
library(nanoparquet)
library(tidyverse)
library(openxlsx)
library(stringi)
library(janitor)
library(uuid)
```

## 2.0 Load data

```{r include=FALSE}
# -------- Paths to exported data files --------
data_dir <- "C:/Users/nmei0013/Downloads"
f_forms <- file.path(data_dir, "export-export_forms_empress_domain_20260120103346.parquet")
f_events <- file.path(data_dir, "export-export_events_empress_platform_20260120103321.parquet")
allocation <- file.path(data_dir, "export-export_allocations_empress_domain_20260120103346.parquet")

# -------- Load data from parquet files --------
EMPRESS_forms <- read_parquet(f_forms)
EMPRESS_events <- read_parquet(f_events)
EMPRESS_allocation <- read_parquet(allocation)
```

## 3.0 Data validation

### 3.x Code for safety report included cut off

```{r eval=FALSE, include=FALSE}
# 1) Cutoff date
Safety_trigger_date <- date("2026-02-18")
cuttoff_date <- Safety_trigger_date - days(105) + 1

# 2) Subset of enrolled participants in INCEPT-Albumin <= cuttoff_date
EMPRESS_master_safety <- EMPRESS_events %>% 
  filter(
      event_type_name == "enrolment" &
      event_description == "empress_platform" &
      
    # Local datetime for enrolment before cuttoff date
      date(with_tz(timestamp, "Europe/Copenhagen")) <= cuttoff_date 
  ) %>% 
  
  # Rename timestamp to rand_date_time_utc and event_id to rand_datetime_id
  rename(
    rand_datetime_utc = timestamp,
         ) %>% 
  
  # Keep only relevant colums
  select(ssid, enrolment_site, rand_datetime_utc)
```

### 3.1 Creation of master dataframe consisting of 200 first enrolled (feasibility)

```{r}
EMPRESS_master_feasibility <- EMPRESS_events %>% 
  # keep only enrolment rows
  filter(str_detect(event_type_name, "enrolment")) %>% 
  
  # order by time to pick the FIRST 200 enrolled participants
  arrange(timestamp) %>% 
  
  # pick first 200 unique ssid
  distinct(ssid, .keep_all = TRUE) %>% 
  slice_head(n = 200) %>% 
  
  # rename timestamp and event_id
  rename(
    rand_datetime_utc = timestamp,
    rand_datetime_id  = event_id
  ) %>% 
  
  # convert UTC to local datetime
  mutate(
    rand_datetime_local = with_tz(rand_datetime_utc, "Europe/Copenhagen")
  ) %>% 
  
  # keep only relevant columns
  select(
    ssid,
    enrolment_site,
    rand_datetime_utc
  )
```

### 3.2 Remove excluded ssids

```{r}
# 1) Excluded ssids <= cuttoff_date
EMPRESS_excluded_ssid <- EMPRESS_events %>% 
  filter(
      event_type_name == "exclusion" &
      event_description == "empress_platform"
  ) %>% 
  mutate(
     # Local datetime for exclusion before cuttoff date
      date(with_tz(timestamp, "Europe/Copenhagen")) 
  ) %>% pull(ssid)
```

### 3.3 Removal of unwanted spillovers and uuid

```{r}
# ----------------------------
# 1) Scan for Pyhton spill-over
# ----------------------------
py_obj_summary_forms <- EMPRESS_forms %>% 
  mutate(value_chr = as.character(value)) %>% 
  summarise(
    n_py_object = sum(str_detect(value_chr, "<object\\s"), na.rm = TRUE),
    .by = variable_name
  ) %>% 
  filter(n_py_object > 0) %>% 
  arrange(desc(n_py_object))

# ----------------------------
# 2) Query-ready table of affected rows
# ----------------------------
py_obj_rows_forms <- EMPRESS_forms %>%
  mutate(value_chr = as.character(value)) %>%
  filter(str_detect(value_chr, "^<object object at 0x[0-9a-fA-F]+>$")) %>%
  transmute(
    ssid, responsible_site, form_layout, start_datetime, end_datetime,
    variable_name, value = value_chr
  )

# ----------------------------
# 2) Clean forms data from python spill-over
# ----------------------------
EMPRESS_forms <- EMPRESS_forms %>%
  mutate(
    value_chr = stringr::str_squish(as.character(value)),
    value_chr = dplyr::if_else(
      stringr::str_detect(value_chr, "^<object object at 0x[0-9a-fA-F]+>$"),
      NA_character_,
      value_chr
    ),
    value = value_chr
  ) %>%
  select(-value_chr)

# ----------------------------
# 3) Scan for UUID
# ----------------------------
uuid_obj_summary_forms <- EMPRESS_forms %>% 
  mutate(value_chr = str_squish(as.character(value))) %>% 
  summarise(
    n_UUID_object = sum(UUIDvalidate(value_chr), na.rm = TRUE),
    .by = variable_name
  ) %>% 
  filter(n_UUID_object > 0) %>% 
  arrange(desc(n_UUID_object))

# ----------------------------
# 4) Query-ready table of affected rows
# ----------------------------
uuid_obj_rows_forms <- EMPRESS_forms %>%
  mutate(value_chr = str_squish(as.character(value))) %>%
  filter(UUIDvalidate(value_chr) == TRUE) %>% 
  transmute(
    ssid, responsible_site, form_layout, start_datetime, end_datetime,
    variable_name, value = value_chr
  )

# ----------------------------
# 5) Clean forms data from python spill-over
# ----------------------------
EMPRESS_forms <- EMPRESS_forms %>%
  mutate(
    value_chr = str_squish(as.character(value)),
    value_chr = if_else(
      UUIDvalidate(value_chr) == TRUE, 
      NA_character_,
      value_chr
    ),
    value = value_chr
  ) %>%
  select(-value_chr)

rm(
  py_obj_rows_forms,
  py_obj_summary_forms,
  uuid_obj_rows_forms,
  UUID_obj_summary_forms
)
```

### 3.4

```{r}

```

## 4.0 Data cleaning
